{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom library integration - PyTorch example\n",
    "\n",
    "DDS can deal with arbitrary Python pickle objects, which covers a large range of use cases. This is not enough for specialized libraries that may have their own storage formats. This example takes a simple pytorch example and shows how to add support for custom objects in DDS.\n",
    "\n",
    "The original example is at https://github.com/pytorch/examples/blob/master/regression/main.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import functools\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "POLY_DEGREE = 4\n",
    "\n",
    "# Because randn is not idempotent, it needs to be wrapped to ensure it is executed once\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def W_target(): return torch.randn(POLY_DEGREE, 1) * 5\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def b_target(): return torch.randn(1) * 5\n",
    "\n",
    "\n",
    "def make_features(x):\n",
    "    \"\"\"Builds features i.e. a matrix with columns [x, x^2, x^3, x^4].\"\"\"\n",
    "    x = x.unsqueeze(1)\n",
    "    return torch.cat([x ** i for i in range(1, POLY_DEGREE+1)], 1)\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Approximated function.\"\"\"\n",
    "    return x.mm(W_target()) + b_target().item()\n",
    "\n",
    "\n",
    "def poly_desc(W, b):\n",
    "    \"\"\"Creates a string description of a polynomial.\"\"\"\n",
    "    result = 'y = '\n",
    "    for i, w in enumerate(W):\n",
    "        result += '{:+.2f} x^{} '.format(w, i + 1)\n",
    "    result += '{:+.2f}'.format(b[0])\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_batch(batch_size=32):\n",
    "    \"\"\"Builds a batch i.e. (x, f(x)) pair.\"\"\"\n",
    "    random = torch.randn(batch_size)\n",
    "    x = make_features(random)\n",
    "    y = f(x)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first difference with the example is that all the PyTorch variables should be in a function. If they are just top-level variables, they will be ignored during the calculation of the checksums of the final outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.000630 after 301 batches\n",
      "==> Learned function:\ty = +3.28 x^1 +1.33 x^2 +0.35 x^3 +3.12 x^4 +2.92\n",
      "==> Actual function:\ty = +3.31 x^1 +1.33 x^2 +0.31 x^3 +3.11 x^4 +2.92\n"
     ]
    }
   ],
   "source": [
    "def train_function():\n",
    "    \n",
    "    # Define model\n",
    "    fc = torch.nn.Linear(W_target().size(0), 1)\n",
    "\n",
    "    for batch_idx in count(1):\n",
    "        # Get data\n",
    "        batch_x, batch_y = get_batch()\n",
    "\n",
    "        # Reset gradients\n",
    "        fc.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = F.smooth_l1_loss(fc(batch_x), batch_y)\n",
    "        loss = output.item()\n",
    "\n",
    "        # Backward pass\n",
    "        output.backward()\n",
    "\n",
    "        # Apply gradients\n",
    "        for param in fc.parameters():\n",
    "            param.data.add_(-0.1 * param.grad)\n",
    "\n",
    "        # Stop criterion\n",
    "        if loss < 1e-3:\n",
    "            return loss, batch_idx, fc\n",
    "\n",
    "# Let's check first that the function works correctly:\n",
    "\n",
    "loss, batch_idx, fc = train_function()\n",
    "\n",
    "print('Loss: {:.6f} after {} batches'.format(loss, batch_idx))\n",
    "print('==> Learned function:\\t' + poly_desc(fc.weight.view(-1), fc.bias))\n",
    "print('==> Actual function:\\t' + poly_desc(W_target().view(-1), b_target()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
